{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7f8b8739-f1dc-4107-8d8f-127a9c508e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac although the Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxuxy Air Mattress</td>\n",
       "      <td>This mattress has a small holw in the top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow filters on Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld</td>\n",
       "      <td>I loved this product. But they only seem to lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Product                                             Review\n",
       "0    Queen Size Sheet Set  I ordered a king size set. My only criticism with\n",
       "1  Waterproof Phone Pouch       I loved the waterproof sac although the Open\n",
       "2     Luxuxy Air Mattress          This mattress has a small holw in the top\n",
       "3          Pillows Insert    This is the best throw pillow filters on Amazon\n",
       "4   Milk Frother Handheld  I loved this product. But they only seem to lo..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "92cbd746-5ff4-4642-b545-9b39a0b37586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import qianfan\n",
    "from langchain_community.llms import QianfanLLMEndpoint\n",
    "from langchain_community.chat_models import QianfanChatEndpoint\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = QianfanLLMEndpoint(streaming=True, model=\"ERNIE-Speed-128K\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ad00db84-20db-40c9-a9b8-86307ecfed5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The best name to describe a company that makes the Queen Size Sheet Set would be something related to the product itself, such as \"Queen Size Bed Sheets Manufacturers\" or \"Luxury Bed Sheet Company.\" Alternatively, you can also use more abstract names that suggest the qualities or values associated with the product, such as \"Premium Bedding Solutions,\" \"Elegant Sleep Innovators,\" or \"Dream Bed Sheets.\" Ensure that the name you choose is unique and reflects the unique selling proposition of your company.'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"What is the best name to describe a company that makes the {product}?\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm\n",
    "product = \"Queen Size Sheet Set\"\n",
    "chain.invoke(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3856eda0-9359-452c-98b9-131832a48397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5e4cd74e-d520-4797-a29b-eae11428ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = ChatPromptTemplate.from_template(\"What is the name of the company that makes the {product}?\")\n",
    "chain = first_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "210c431a-4136-4f17-8aef-fbab33d87183",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\"write a 20 words description for the following company : {company}.\")\n",
    "chain_two = second_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4165e7c2-6a96-43ed-8c56-3d5e6b65e1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple Inc. is the leading technology company that innovates and manufactures the world-renowned iPhone.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain = {\"company\" : chain} | chain_two\n",
    "\n",
    "phone = \"iPhone\"\n",
    "overall_simple_chain.invoke(phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "86fa76ad-aea8-47e9-83d2-57f6074add29",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a comon way. \\\n",
    "When you don't know the answer to a question you admit that.\n",
    "\n",
    "Here is a question:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "math_template = \"\"\"\n",
    "You are a very good mathematician. \\\n",
    "You are so good because you are able to brean down hard problem into components \\\n",
    "and answer the component parts, and then put them together to answer.\n",
    "\n",
    "Here is a question:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "history_template = \"\"\"\n",
    "You are a very good historian. YOu have contexts from a range of historical periods. You have \\\n",
    "the ability to evaluate the past. You have a respect for historical evidence on your \\\n",
    "explanations and judgements.\n",
    "\n",
    "Here is a questions:\n",
    "{input}\"\"\"\n",
    "\n",
    "computerscience_template = \"\"\"\n",
    "You are a successful computer scientist. You have a passion \\\n",
    "on forward-thinking, confidence, strong problem-solving capability \\\n",
    "YOu are so good because you know how to solve a problem by algorithm \\\n",
    "so that a machine can easily interpret and you know how to check time complexity and space complexity.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d5daa479-a783-411a-93bd-c9117412832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\",\n",
    "        \"description\": \"Good for answering questions about physics.\",\n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\",\n",
    "        \"description\": \"Good for answering questions about math.\",\n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\",\n",
    "        \"description\": \"Good for answering History questions.\",\n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\",\n",
    "        \"description\": \"Good for answering computer science questions.\",\n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "    \n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8e1de1d5-437e-4f61-9951-256531217439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "    chain = prompt | llm # | LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destination_str = \"\\n\".join(destinations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cde17dac-d578-4950-b74a-24fb12509cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = default_prompt | llm #LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9d5dfb91-3d47-448b-ae42-ba7967fe3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"\n",
    "Given a raw text input to \n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON Object formatted.\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"\"\n",
    "    \"next_inputs\": string \\ a potentially modified version\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt\n",
    "REMEMBER: \"next_inputs\" can just be the original input if y\n",
    "\n",
    "<< CANDINATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<<INPUT>>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8bb53aa8-8a61-42e8-a3c5-ed9cea01510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destination_str)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_varibales={\"input\"},\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = router_prompt | llm | RouterOutputParser() # LLMRouterChain.from_llm(llm, router_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e4324034-2d4c-4802-85d0-1572f7a9519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chain = MultiPromptChain(router_chain=router_chain, destination_chains = destination_chains, default_chain=default_chain, verbose=True)\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "chain = {\n",
    "    \"destination\": router_chain,  # \"animal\" or \"vegetable\"\n",
    "    \"input\": lambda x: x[\"input\"],  # pass through input query\n",
    "} | RunnableLambda(\n",
    "    # if animal, chain_1. otherwise, chain_2.\n",
    "    lambda x: get_dest(x)\n",
    ")\n",
    "\n",
    "def get_dest(x):\n",
    "    print(x)\n",
    "    return destination_chains[x[\"destination\"][\"destination\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7c62d365-c15a-4ce5-970e-2d4efb3d6c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'destination': {'destination': 'physics', 'next_inputs': {'input': 'What is black body radiation ?'}}, 'input': 'What is black body rediation ?'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Thank you for your kind words and recognition. I'm here to assist with your question about black body radiation.\\n\\nBlack body radiation refers to the electromagnetic radiation emitted by a black body, which is an idealized surface that completely absorbs all wavelengths of electromagnetic radiation incident upon it, regardless of its direction of incidence. In other words, a black body is an idealized object that doesn't reflect any light, and therefore it can emit radiation efficiently into the surrounding environment. The emitted radiation follows a specific pattern that is described by Planck's law, which states that the radiation emitted by a black body is made up of energy quanta called photons and has a continuous distribution across the electromagnetic spectrum. The concept of black body radiation has many practical applications, including engineering and materials research. It's worth mentioning that when a certain frequency range of electromagnetic waves strikes a material, the material can absorb the waves, reflect them, or emit them. For example, objects that are particularly efficient at emitting black body radiation are called black bodies or blackbodies in common language.\\n\\nI hope this explanation clarifies your question about black body radiation. If you have any further questions or need additional clarification on any topics related to physics, please feel free to ask!\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"What is black body rediation ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c4334226-9ae5-43e0-b263-3685b5efdcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'destination': {'destination': 'History', 'next_inputs': {'input': 'when does the Tang dynasty start ?'}}, 'input': 'when does the Tang dynasty start ?'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Tang dynasty began in 618 AD, following the collapse of the Sui dynasty.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"when does the Tang dynasty start ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "291a4608-76d6-4dde-a742-46465c4d3c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History: {'input': 'when was the tea been thrown to the port in Boston ?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'when was the tea been thrown to the port in Boston ?',\n",
       " 'text': \"The Boston Tea Party occurred on December 16, 1773. It was a political protest against the East India Company's monopoly on tea imports and the high taxes on tea in the British colonies in America. During this event, a group of colonists boarded ships at Boston Harbor and threw the tea overboard in protest.\"}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"when was the tea been thrown to the port in Boston ? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0781572-8a78-4acc-91af-5ed6852c6864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math: {'input': 'what is 100 multiple 10 ?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is 100 multiple 10 ?',\n",
       " 'text': 'I can be good at mathematics, but I am not perfect.\\n\\nThe answer to your question is: 100 multiplied by 10 is 1000.'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"what is 100 multiple 10 ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f08aa-ba87-48c7-a8ed-293301536ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
